{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fe4f4a5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /home/isaacs07/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /home/isaacs07/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from transformers) (2.28.1)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /home/isaacs07/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/isaacs07/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from transformers) (2022.9.13)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/isaacs07/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/isaacs07/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from transformers) (1.23.4)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.9.0-py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/isaacs07/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/isaacs07/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/isaacs07/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from requests->transformers) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/isaacs07/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from requests->transformers) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/isaacs07/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/isaacs07/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Installing collected packages: tokenizers, filelock, huggingface-hub, transformers\n",
      "Successfully installed filelock-3.9.0 huggingface-hub-0.12.1 tokenizers-0.13.2 transformers-4.26.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1704a15e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3a3e0d7da674bfcb949ceefeb976ef6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dfd968fadf7402ca432c22905d4a180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"tf_model.h5\";:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-07 11:29:38.370878: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-03-07 11:29:38.371487: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-07 11:29:38.371639: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Zakaria): /proc/driver/nvidia/version does not exist\n",
      "2023-03-07 11:29:38.373824: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-07 11:29:38.553580: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 154389504 exceeds 10% of free system memory.\n",
      "2023-03-07 11:29:38.642083: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 154389504 exceeds 10% of free system memory.\n",
      "2023-03-07 11:29:38.707049: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 154389504 exceeds 10% of free system memory.\n",
      "2023-03-07 11:29:40.321266: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 154389504 exceeds 10% of free system memory.\n",
      "2023-03-07 11:29:42.824543: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 154389504 exceeds 10% of free system memory.\n",
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0b63fda90f44617b0bdc291d3da988a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfb81fdf1b97410ebf9ad5e0e7c76921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a38b4bdbe4bb4acb9098b4e6d746296b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28906420486f4bb58c076a5f0794e8b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/isaacs07/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/transformers/generation/tf_utils.py:603: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"Hello, I'm a language model, and its my job to write my own.\\n\\nNow how did I learn the language? Before I began\"},\n",
       " {'generated_text': \"Hello, I'm a language model, so this is not really a problem. It's actually a really good concept, especially compared to trying to build\"},\n",
       " {'generated_text': \"Hello, I'm a language model, a language model.\\n\\nMy goal is to show you all the concepts taught and then to talk about them\"},\n",
       " {'generated_text': 'Hello, I\\'m a language model, and I like being part of software development,\" Poonam said. \"I hope that I\\'ve come up'},\n",
       " {'generated_text': 'Hello, I\\'m a language model, I\\'m a teacher, I\\'m a model of excellence, of the future of education.\" The teacher\\'s office'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "set_seed(42)\n",
    "generator(\"Hello, I'm a language model,\", max_length=30, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "37c2b2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "/home/isaacs07/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/transformers/generation/tf_utils.py:603: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline('text-generation', model='gpt2')\n",
    "set_seed(42)\n",
    "generated = generator(\"Once upon a time\", max_length=1024, num_return_sequences=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bfa2238c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "802"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(generated[0]['generated_text'].split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d2c6bd2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Once upon a time, these things would have happened. The other way around was by allowing the Church to give them permission to conduct some things in their names, including all those things under the authority of St. Paul. But there is another way in, we think, that we\\'re at it, which is to say to them, \"We\\'ve been given this special privilege by Heaven.\" And if they\\'re in heaven and they want to do things. If they really want to do things, they can. And that\\'s just a choice, you know, to make, I think, what\\'s it going to be about? I\\'m willing to say at the end of the day, it\\'s all very different. You have to be careful there. You can\\'t just, \"Look at that, look at that! I gotta tell you how I\\'m gonna be in heaven.\" There are so many issues, there are so many things going this way that, it makes sense to just give them permission. And you can have a lot of control over one another as a Catholic church or a church organization.\\n\\nSo is it really that simple to just say we have to give them permission? No. It\\'s more complicated. Certainly, as I said above, I thought in a book last week that we had to do something like that. I mean, you see these people have had the authority of some priests in the past, you see these people being allowed as pastors to make a decision without having to be called by God. I\\'m sure they\\'re doing that, of course.\\n\\nI think perhaps people will consider that to be blasphemy — that it\\'s something some of us are going to have to do.\\n\\nBENDS: I believe that, Mr. President, the Church is a moral institution, a human institution. It\\'s a system for us. It\\'s also a family organization, it\\'s a sacred organization, it\\'s an apostolate. And this is the way this is going to work. You\\'ve got something really holy there that I haven\\'t heard of. My grandfather raised the young boys. The great-grandfather passed away two or three years ago. All of his children have been blessed. God gave him a little bit of immortality, as the Elder General did after the Napoleonic War, and he\\'s been blessed as a bishop, as an emissary for this church. But, as if to say, \"Hey, Mr. President, if I was going to do things like that and don\\'t tell my kids for some reason, they, you know, have to be given an authority, they have to do what they\\'re going to do. No, they\\'re not allowed not to do something like that,\" and so I do not say that. I think that\\'s blasphemy. I\\'m not going to tell my kids that.\\n\\nThey\\'ve got to do what they\\'ve been given to do.\\n\\nI mean, I mean, it\\'s really interesting that in that case, there was someone there, \"My great-grandfather, your great-grandfather passed away. And the people who were there that night, no one knows why they did that.\" And I don\\'t think the Church should tell or even acknowledge that it was their role as missionaries to baptize. It does what it\\'s meant to do.\\n\\nI think it\\'s a kind of blasphemy that they cannot even go back to the time when they baptized, or what they did in those words.\\n\\n(CROSSTALK)\\n\\nBENDS: Well, I don\\'t have to tell you about it, but I did give an interesting, and provocative, talk at a church forum in Baltimore this week, and one man, who was a senior pastor at that time was asked this by a Catholic priest that many people in the church said, well, you know, if we had a little bit more of an issue of the Gospel, the Church could have done something that would have been just as important, if I may, to my personal life by not encouraging abuse. That\\'s a bit like it\\'s a Christian doctrine. What I\\'m saying here comes from a very young age in that I believe that we have to have a moral culture, a moral culture, and that\\'s not going to change in the next 25 years. I hope it does. It\\'s a good start for our future, but you can\\'t go back and push it unless you think it works. And I hope the Church that we have here, and I think we should do our part in this Church as a whole, that we will keep our promises before the end of the 21 century. Let all of us take responsibility, and let everybody think before the end of the 21 century. And then, Mr. President, let\\'s follow the prophet from here.\\n\\nBENDS: I\\'m sure there\\'s a lot of other people who, well, at least I\\'m glad, the Church would work very hard for us to help'}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdaeb04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e26b467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>The next morning the young prince set forth in...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>\"  Once upon a time there lived in a city of H...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>\"  Once upon a time there was a very rich and ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>\"  Once there lived a certain king who underst...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>\"  In the midst of a sandy desert somewhere in...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6657</th>\n",
       "      <td>6657</td>\n",
       "      <td>Zeri</td>\n",
       "      <td>Welcome to Universe, the definitive source for...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6658</th>\n",
       "      <td>6658</td>\n",
       "      <td>Ziggs</td>\n",
       "      <td>Ziggs was born with a talent for tinkering, bu...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6659</th>\n",
       "      <td>6659</td>\n",
       "      <td>Zilean</td>\n",
       "      <td>Icathia, most desolate and cursed of lands, wa...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6660</th>\n",
       "      <td>6660</td>\n",
       "      <td>Zoe</td>\n",
       "      <td>As befits her Targonian Aspect’s nature, Zoe d...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6661</th>\n",
       "      <td>6661</td>\n",
       "      <td>Zyra</td>\n",
       "      <td>Zyra’s memory is long, and runs as deep as the...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6662 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  ... classification\n",
       "0              0  ...            NaN\n",
       "1              1  ...            NaN\n",
       "2              2  ...            NaN\n",
       "3              3  ...            NaN\n",
       "4              4  ...            NaN\n",
       "...          ...  ...            ...\n",
       "6657        6657  ...            NaN\n",
       "6658        6658  ...            NaN\n",
       "6659        6659  ...            NaN\n",
       "6660        6660  ...            NaN\n",
       "6661        6661  ...            NaN\n",
       "\n",
       "[6662 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../processed_data/final.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "290df742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6592"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.classification.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3aa5e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.989492644851396"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6592/6662"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e38323f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Adventure', 'Parody', 'Humor', 'Adventure,Science_fiction',\n",
       "       'Horror', 'Romance', 'Horror,Humor', 'Sketch', 'Satire',\n",
       "       'Hoax,Science_fiction', 'Science_fiction', 'Horror,Satire',\n",
       "       'Fantasy,Horror', 'Humor,Satire', 'Hoax,Horror,Science_fiction',\n",
       "       'Fantasy', 'Detective_fiction', 'Horror,Ratiocination',\n",
       "       'Detective_fiction,Satire', 'Hoax,Satire', 'Essay', 'Fiction,Hoax'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.classification.isna() == False].classification.unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
